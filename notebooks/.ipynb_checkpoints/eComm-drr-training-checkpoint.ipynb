{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7525ba28-39f6-4284-a088-8018a17e08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379f814c-ae17-48f0-a83d-83ffdc7b6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copyreg import pickle\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from model.model import Actor, Critic, DRRAveStateRepresentation, PMF\n",
    "from learn.learn import DRRTrainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tsmoothie.smoother import ConvolutionSmoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183ca3c4-f462-4818-95e3-50b9f1f4e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    date_time = datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    output_path = '../results/' + date_time + '/'\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    plot_dir = output_path + 'rewards.pdf'\n",
    " \n",
    "    train_actor_loss_data_dir = output_path + 'train_actor_loss_data.npy'\n",
    "    train_critic_loss_data_dir = output_path + 'train_critic_loss_data.npy'\n",
    "    train_mean_reward_data_dir = output_path + 'train_mean_reward_data.npy'\n",
    " \n",
    "    train_actor_loss_plot_dir = output_path + 'train_actor_loss.png'\n",
    "    train_critic_loss_plot_dir = output_path + 'train_critic_loss.png'\n",
    "    train_mean_reward_plot_dir = output_path + 'train_mean_reward.png'\n",
    " \n",
    "    trained_models_dir = '../trained/' + date_time + '/'\n",
    " \n",
    "    actor_model_trained = trained_models_dir + 'actor_net.weights'\n",
    "    critic_model_trained = trained_models_dir + 'critic_net.weights'\n",
    "    state_rep_model_trained = trained_models_dir + 'state_rep_net.weights'\n",
    " \n",
    "    actor_model_dir = output_path + 'actor_net.weights'\n",
    "    critic_model_dir = output_path + 'critic_net.weights'\n",
    "    state_rep_model_dir = output_path + 'state_rep_net.weights'\n",
    " \n",
    "    csv_dir = output_path + 'log.csv'\n",
    " \n",
    "    path_to_trained_pmf = '../trained/trained_pmf.pt'\n",
    " \n",
    "    # hyperparams\n",
    "    batch_size = 128\n",
    "    gamma = 0.9\n",
    "    replay_buffer_size = 100000\n",
    "    history_buffer_size = 5\n",
    "    learning_start = 1000 #5000\n",
    "    learning_freq = 1\n",
    "    lr_state_rep = 0.001\n",
    "    lr_actor = 0.0001\n",
    "    lr_critic = 0.001\n",
    "    eps_start = 1\n",
    "    eps = 0.1\n",
    "    eps_steps = 10000\n",
    "    eps_eval = 0.1\n",
    "    tau = 0.01 # inital 0.001\n",
    "    beta = 0.4\n",
    "    prob_alpha = 0.3\n",
    "    max_timesteps_train = 15000\n",
    "    max_epochs_offline = 500\n",
    "    max_timesteps_online = 2000\n",
    "    embedding_feature_size = 100\n",
    "    episode_length = 10\n",
    "    train_ratio = 0.8\n",
    "    weight_decay = 0.01\n",
    "    clip_val = 1.0\n",
    "    log_freq = 500\n",
    "    saving_freq = 100\n",
    "    zero_reward = False\n",
    " \n",
    "    no_cuda = True\n",
    "    \n",
    "    logs_dir = '../runs/' + date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9266c285-6497-4411-a397-8a97bbce465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(cuda, seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.manual_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca84cada-2793-4280-b060-6234efa7dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DRR Framework ----------------------------------------------------------------------------\n",
      "Using CPU\n",
      "Seeds initialized\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing DRR Framework ----------------------------------------------------------------------------\")\n",
    " \n",
    "# Get CUDA device if available\n",
    "cuda = True if not config.no_cuda and torch.cuda.is_available() else False\n",
    "print(\"Using CUDA\") if cuda else print(\"Using CPU\")\n",
    " \n",
    "# Init seeds\n",
    "seed_all(cuda, 0)\n",
    "print(\"Seeds initialized\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa65e36-db6d-455a-96cb-60a38cc8ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab models\n",
    "actor_function = Actor\n",
    "critic_function = Critic\n",
    "state_rep_function = DRRAveStateRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9653f2a-fb70-47d2-97a2-302031839c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '../dataset/sample_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7408a697-630e-49ad-a439-fefc1bd955b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(CSV_PATH)\n",
    "reward_map = {'view': 1, 'cart': 2, 'purchase': 3}\n",
    "data_df['behavior'] = data_df['event_type'].apply(lambda x : reward_map[x])\n",
    "\n",
    "with open('../dataset/user_num_to_id.pkl', 'rb') as f:\n",
    "    users = pickle.load(f)\n",
    "\n",
    "with open('../dataset/item_num_to_id.pkl', 'rb') as f:\n",
    "    items = pickle.load(f)\n",
    "\n",
    "NUM_USERS, NUM_ITEMS = len(users), len(items)\n",
    "\n",
    "data = data_df.loc[:, ['user_id_num', 'product_id_num', 'behavior', 'event_time']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e957dc-9d15-4020-a844-cb90683dcaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported, shuffled, and split into Train/Test, ratio= 0.8\n",
      "Train data shape:  torch.Size([101065, 4])\n",
      "Test data shape:  torch.Size([25267, 4])\n"
     ]
    }
   ],
   "source": [
    "shuffle(data, random_state=1)\n",
    "train_data = torch.from_numpy(data[:int(config.train_ratio * data.shape[0])])\n",
    "test_data = torch.from_numpy(data[int(config.train_ratio * data.shape[0]):])\n",
    "print(\"Data imported, shuffled, and split into Train/Test, ratio=\", config.train_ratio)\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472b235a-2939-4e26-8c52-8771f27549c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../dataset/test_data.npy', test_data)\n",
    "np.save('../dataset/train_data.npy', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2897a05a-beac-474b-8f9a-9cacbfce008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized PMF, imported weights, created reward_function\n",
      "Extracted user and item embeddings from PMF\n",
      "User embeddings shape:  torch.Size([5380, 100])\n",
      "Item embeddings shape:  torch.Size([15286, 100])\n"
     ]
    }
   ],
   "source": [
    "# Create and load PMF function for rewards and embeddings\n",
    "reward_function = PMF(NUM_USERS, NUM_ITEMS, config.embedding_feature_size, is_sparse=False, no_cuda=~cuda)\n",
    "reward_function.load_state_dict(torch.load(config.path_to_trained_pmf))\n",
    " \n",
    "# Freeze all the parameters in the network\n",
    "for param in reward_function.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"Initialized PMF, imported weights, created reward_function\")\n",
    " \n",
    "# Extract embeddings\n",
    "user_embeddings = reward_function.user_embeddings.weight.data\n",
    "item_embeddings = reward_function.item_embeddings.weight.data\n",
    "print(\"Extracted user and item embeddings from PMF\")\n",
    "print(\"User embeddings shape: \", user_embeddings.shape)\n",
    "print(\"Item embeddings shape: \", item_embeddings.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74d3241-3fa0-426e-a3c3-c3c8f6d324dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DRRTrainer -------------------------------------------------------------------------------\n",
      "Current PyTorch Device:  cpu\n",
      "Data dimensions extracted\n",
      "Models initialized\n",
      "Model weights initialized, copied to target\n",
      "Optimizers initialized\n"
     ]
    }
   ],
   "source": [
    "# Init trainer\n",
    "print(\"Initializing DRRTrainer -------------------------------------------------------------------------------\")\n",
    "trainer = DRRTrainer(config,\n",
    "                      actor_function,\n",
    "                      critic_function,\n",
    "                      state_rep_function,\n",
    "                      reward_function,\n",
    "                      users,\n",
    "                      items,\n",
    "                      train_data,\n",
    "                      test_data,\n",
    "                      user_embeddings,\n",
    "                      item_embeddings,\n",
    "                      cuda\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b71737c-824e-49d7-b126-d8b7aff51a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DRRTrainer.learn() ---------------------------------------------------------------------------\n",
      "User id 3838, Episode 0, step 1, timestamp 181 rec item 647, reward 2.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankurdhuriya/RL_UseCase/drr/notebooks/../learn/learn.py:267: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ignored_items.append(torch.tensor(rec_item_idx).to(self.device))\n",
      "/Users/ankurdhuriya/miniconda3/envs/drr_pytorch/lib/python3.10/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 500 | Episode 49 | Mean Ep R 3.0000 | Max R 3.0000 | Critic Params Norm 1.3940 | Actor Loss -11.4000 | Critic Loss 0.0355 | \n",
      "Timestep 1000 | Episode 99 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 4.0355 | Actor Loss -17.6124 | Critic Loss 0.0774 | \n",
      "Timestep 1500 | Episode 149 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 6.7441 | Actor Loss -21.0875 | Critic Loss 0.1110 | \n",
      "Timestep 2000 | Episode 199 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 3.7369 | Actor Loss -24.3092 | Critic Loss 0.0597 | \n",
      "Timestep 2500 | Episode 249 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 22.8974 | Actor Loss -24.2616 | Critic Loss 0.4277 | \n",
      "Timestep 3000 | Episode 299 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 3.7331 | Actor Loss -26.1402 | Critic Loss 0.0749 | \n",
      "Timestep 3500 | Episode 349 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 11.3472 | Actor Loss -27.0521 | Critic Loss 0.1299 | \n",
      "Timestep 4000 | Episode 399 | Mean Ep R 3.0000 | Max R 3.0000 | Critic Params Norm 26.5713 | Actor Loss -26.6781 | Critic Loss 0.4406 | \n",
      "Timestep 4500 | Episode 449 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 12.6951 | Actor Loss -27.8462 | Critic Loss 0.1189 | \n",
      "Timestep 5000 | Episode 499 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 23.3133 | Actor Loss -27.1068 | Critic Loss 0.2818 | \n",
      "Timestep 5500 | Episode 549 | Mean Ep R 2.0000 | Max R 2.0000 | Critic Params Norm 15.9039 | Actor Loss -26.1657 | Critic Loss 0.1513 | \n",
      "Timestep 6000 | Episode 599 | Mean Ep R 3.0000 | Max R 3.0000 | Critic Params Norm 41.5600 | Actor Loss -25.0111 | Critic Loss 0.7668 | \n",
      "Training Finishedsode 599, step 9, timestamp 7009 rec item 435, reward 3.00\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Starting DRRTrainer.learn() ---------------------------------------------------------------------------\")\n",
    "actor_losses, critic_losses, epi_avg_rewards = trainer.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd4763e-5051-4200-9d0b-41219b0576aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseless_plot(y, title, ylabel, save_loc):\n",
    "    smoother = ConvolutionSmoother(window_len=1000, window_type='ones')\n",
    "    smoother.smooth(y)\n",
    "\n",
    "    # generate intervals\n",
    "    low, up = smoother.get_intervals('sigma_interval', n_sigma=3)\n",
    "\n",
    "    # plot the smoothed timeseries with intervals\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(11,6))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.plot(smoother.data[0], color='orange')\n",
    "    plt.plot(smoother.smooth_data[0], linewidth=3, color='blue')\n",
    "    plt.fill_between(range(len(smoother.data[0])), low[0], up[0], alpha=0.3)\n",
    "    plt.savefig(save_loc)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa3556c-ef73-40bd-9b69-1217b7da33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_losses = np.load(config.train_actor_loss_data_dir)\n",
    "critic_losses = np.load(config.train_critic_loss_data_dir)\n",
    "epi_avg_rewards = np.load(config.train_mean_reward_data_dir)\n",
    "\n",
    "noiseless_plot(actor_losses, \n",
    "               \"Actor Loss (Train)\", \n",
    "               \"Actor Loss (Train)\", \n",
    "               config.output_path + \"train_actor_loss_smooth.png\")\n",
    "               \n",
    "noiseless_plot(critic_losses, \n",
    "               \"Critic Loss (Train)\", \n",
    "               \"Critic Loss (Train)\", \n",
    "               config.output_path + \"train_critic_loss_smooth.png\")\n",
    "\n",
    "noiseless_plot(epi_avg_rewards, \n",
    "               \"Mean Reward (Train)\", \n",
    "               \"Mean Reward (Train)\", \n",
    "               config.output_path + \"train_mean_reward_smooth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ae3c55-7db9-4c67-8c96-d839893d1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile = open(config.output_path + \"hyperparams.txt\", 'w')\n",
    "print(config.__dict__, file = sourceFile)\n",
    "sourceFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13a0bc-df2c-40b0-8778-14df48362b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
